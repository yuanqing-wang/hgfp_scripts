{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:58:25] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Warning: Unable to load toolkit 'OpenEye Toolkit'. The Open Force Field Toolkit does not require the OpenEye Toolkits, and can use RDKit/AmberTools instead. However, if you have a valid license for the OpenEye Toolkits, consider installing them for faster performance and additional file format support: https://docs.eyesopen.com/toolkits/python/quickstart-python/linuxosx.html OpenEye offers free Toolkit licenses for academics: https://www.eyesopen.com/academic-licensing\n"
     ]
    }
   ],
   "source": [
    "import hgfp\n",
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangy1/anaconda3/envs/env1/lib/python3.7/site-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
      "  warnings.warn(msg, warn_type)\n"
     ]
    }
   ],
   "source": [
    "ds = list(hgfp.data.parm_at_Frosst.df.batched(num=1000, batch_size=10, use_fp=False))\n",
    "ds_tr, ds_vl, ds_te = hgfp.data.utils.split(ds, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import pytorch as dgl_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GN(torch.nn.Module):\n",
    "    def __init__(self, model, kwargs):\n",
    "        super(GN, self).__init__()\n",
    "        self.gn = model(64, 64, **kwargs)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        g_sub = dgl.to_homo(\n",
    "            g.edge_type_subgraph(['atom_neighbors_atom']))\n",
    "        x = self.gn(g_sub, x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, in_dim=128, out_dim=256, n_classes=45):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.d = torch.nn.Linear(in_dim, out_dim)\n",
    "        self.c = torch.nn.Linear(out_dim, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_hat = self.c(\n",
    "                torch.nn.functional.tanh(\n",
    "                    self.d(\n",
    "                        x)))\n",
    "        \n",
    "        return y_hat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, model, kwargs):\n",
    "        super(Net, self).__init__()\n",
    "        self.f_in = torch.nn.Sequential(\n",
    "            torch.nn.Linear(117, 64),\n",
    "            torch.nn.Tanh())\n",
    "        \n",
    "        self.gn0 = GN(model, kwargs)\n",
    "        self.gn1 = GN(model, kwargs)\n",
    "        self.gn2 = GN(model, kwargs)\n",
    "        \n",
    "        self.c = Classifier(64, 64, 45)\n",
    "        \n",
    "    def forward(self, g):\n",
    "        x = g.nodes['atom'].data['h0']\n",
    "        x = self.f_in(x)\n",
    "        x = self.gn0(g, x)\n",
    "        x = torch.nn.functional.tanh(x)\n",
    "        x = self.gn1(g, x)\n",
    "        x = torch.nn.functional.tanh(x)\n",
    "        x = self.gn2(g, x)\n",
    "        x = self.c(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGEConvMean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangy1/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in {\n",
    "        # 'GraphConv': [dgl_pytorch.conv.GraphConv, {}],\n",
    "        # 'TAGConv': [dgl_pytorch.conv.TAGConv, {}],\n",
    "        # 'EdgeConv': [dgl_pytorch.conv.EdgeConv, {}],\n",
    "        'SAGEConvMean': [dgl_pytorch.conv.SAGEConv, {'aggregator_type': 'mean'}],\n",
    "        # 'SAGEConvGCN': [dgl_pytorch.conv.SAGEConv, {'aggregator_type': 'gcn'}],\n",
    "        # 'SAGEConvPool': [dgl_pytorch.conv.SAGEConv, {'aggregator_type': 'pool'}],\n",
    "        # 'SAGEConvLSTM': [dgl_pytorch.conv.SAGEConv, {'aggregator_type': 'lstm'}],\n",
    "        # 'SGConv': [dgl_pytorch.conv.SGConv, {}]\n",
    "}.items():\n",
    "\n",
    "    print(model_name)\n",
    "    net=Net(model[0], model[1])\n",
    "    opt = torch.optim.Adam(list(net.parameters()), 1e-3)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    namespace = __import__(__name__)\n",
    "\n",
    "    for part in ['tr', 'vl', 'te']:\n",
    "        exec('accuracy_' + part + '= []')\n",
    "\n",
    "    for _ in range(500):\n",
    "        for g, y in ds_tr:\n",
    "            opt.zero_grad()\n",
    "            y_hat = net(g)\n",
    "            loss = loss_fn(y_hat, torch.where(torch.gt(y, 0))[1])\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        net.eval()\n",
    "        for part in ['tr', 'vl', 'te']:\n",
    "            y_hat = torch.cat([torch.argmax(net(g), dim=1) for g, y in getattr(\n",
    "                namespace, 'ds_' + part)], dim=0).detach().numpy()\n",
    "\n",
    "            y = torch.cat([torch.argmax(y, dim=1) for g, y in getattr(\n",
    "                namespace, 'ds_' + part)], dim=0).detach().numpy()\n",
    "\n",
    "            getattr(namespace, 'accuracy_' + part).append(\n",
    "                1 - np.divide(\n",
    "                    np.count_nonzero(y_hat - y),\n",
    "                y_hat.shape[0]))\n",
    "\n",
    "        net.train()\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.figure()\n",
    "    plt.plot(accuracy_tr, label='training')\n",
    "    plt.plot(accuracy_vl, label='validation')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('n_epochs')\n",
    "    plt.title(model_name)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(model_name + '.png', dpi=500)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015371621621621622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangy1/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_hat = torch.cat([torch.argmax(net(g), dim=1) for g, y in ds_vl+ds_te], axis=0)\n",
    "y = torch.cat([torch.argmax(y, dim=1) for g, y in ds_vl+ds_te], axis=0)\n",
    "\n",
    "print(np.count_nonzero(y - y_hat) / y_hat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_to_idx = {b'BR': 0, b'C': 1, b'C2': 2, b'CA': 3, b'CB': 4, b'CC': 5, b'CJ': 6, b'CL': 7, b'CM': 8, b'CP': 9, b'CR': 10, b'CT': 11, b'CW': 12, b'Cstar': 13, b'F': 14, b'H': 15, b'H1': 16, b'H2': 17, b'H3': 18, b'H4': 19, b'H5': 20, b'HA': 21, b'HC': 22, b'HO': 23, b'HP': 24, b'HX': 25, b'I': 26, b'N': 27, b'N2': 28, b'N3': 29, b'NA': 30, b'NB': 31, b'NC': 32, b'NL': 33, b'Nstar': 34, b'Nu': 35, b'O': 36, b'O2': 37, b'OH': 38, b'OS': 39, b'Ou': 40, b'P': 41, b'S': 42, b'SO': 43, b'Su': 44}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_element = {v: k.decode(\"utf-8\") for k, v in element_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusion_matrix(y, y_hat, labels=list(range(1, 46))),\n",
    "    [v for k, v in idx_to_element.items()],\n",
    "    [v for k, v in idx_to_element.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB -> CA : 7\n",
      "CM -> CA : 7\n",
      "CT -> CB : 6\n",
      "CA -> CB : 5\n",
      "CA -> CT : 5\n",
      "CB -> CT : 5\n",
      "C2 -> CL : 4\n",
      "CA -> C2 : 4\n",
      "H3 -> H5 : 4\n",
      "CA -> CM : 3\n",
      "CT -> CA : 3\n",
      "CP -> CB : 2\n",
      "C2 -> CA : 2\n",
      "CL -> C2 : 2\n",
      "CP -> BR : 2\n",
      "NL -> N : 2\n",
      "BR -> CP : 2\n",
      "CT -> CL : 2\n",
      "HO -> H : 2\n",
      "N2 -> NL : 2\n",
      "N -> I : 1\n",
      "C2 -> BR : 1\n",
      "NB -> NA : 1\n",
      "NA -> N : 1\n",
      "C2 -> CP : 1\n",
      "N2 -> N : 1\n",
      "N2 -> I : 1\n",
      "N -> N2 : 1\n",
      "CA -> CW : 1\n",
      "CB -> CL : 1\n",
      "CW -> CP : 1\n",
      "N -> Cstar : 1\n",
      "CJ -> P : 1\n",
      "I -> N3 : 1\n",
      "CL -> CB : 1\n",
      "I -> N : 1\n",
      "CM -> CB : 1\n",
      "H2 -> H1 : 1\n",
      "CP -> CW : 1\n",
      "NL -> NA : 1\n"
     ]
    }
   ],
   "source": [
    "count_matrix = df_cm.values\n",
    "wrong_idxs = np.stack(np.where(np.greater(count_matrix, 0)), axis=1)\n",
    "wrong_idxs = wrong_idxs[wrong_idxs[:, 0] != wrong_idxs[:, 1]]\n",
    "wrong_count = np.array([count_matrix[idxs[0]][idxs[1]] for idxs in wrong_idxs])\n",
    "wrong_count_argsort = np.flip(np.argsort(wrong_count))\n",
    "for idx in wrong_count_argsort:\n",
    "    print('%s -> %s : %s'%(\n",
    "        idx_to_element[wrong_idxs[idx][0]],\n",
    "        idx_to_element[wrong_idxs[idx][1]],\n",
    "        wrong_count[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
