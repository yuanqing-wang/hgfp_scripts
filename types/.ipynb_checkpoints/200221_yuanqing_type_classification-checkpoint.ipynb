{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [13:44:10] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Warning: Unable to load toolkit 'OpenEye Toolkit'. The Open Force Field Toolkit does not require the OpenEye Toolkits, and can use RDKit/AmberTools instead. However, if you have a valid license for the OpenEye Toolkits, consider installing them for faster performance and additional file format support: https://docs.eyesopen.com/toolkits/python/quickstart-python/linuxosx.html OpenEye offers free Toolkit licenses for academics: https://www.eyesopen.com/academic-licensing\n"
     ]
    }
   ],
   "source": [
    "import hgfp\n",
    "import torch\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_to_idx = {b'BR': 0, b'C': 1, b'C2': 2, b'CA': 3, b'CB': 4, b'CC': 5, b'CJ': 6, b'CL': 7, b'CM': 8, b'CP': 9, b'CR': 10, b'CT': 11, b'CW': 12, b'Cstar': 13, b'F': 14, b'H': 15, b'H1': 16, b'H2': 17, b'H3': 18, b'H4': 19, b'H5': 20, b'HA': 21, b'HC': 22, b'HO': 23, b'HP': 24, b'HX': 25, b'I': 26, b'N': 27, b'N2': 28, b'N3': 29, b'NA': 30, b'NB': 31, b'NC': 32, b'NL': 33, b'Nstar': 34, b'Nu': 35, b'O': 36, b'O2': 37, b'OH': 38, b'OS': 39, b'Ou': 40, b'P': 41, b'S': 42, b'SO': 43, b'Su': 44}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_element = {v: k.decode(\"utf-8\") for k, v in element_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangy1/anaconda3/envs/env1/lib/python3.7/site-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
      "  warnings.warn(msg, warn_type)\n"
     ]
    }
   ],
   "source": [
    "ds = list(hgfp.data.parm_at_Frosst.df.batched(num=100, batch_size=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tr, ds_vl, ds_te = hgfp.data.utils.split(ds, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GN(torch.nn.Module):\n",
    "    def __init__(self, model, kwargs):\n",
    "        super(GN, self).__init__()\n",
    "        self.gn = model(64, 64, **kwargs)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        g_sub = dgl.to_homo(\n",
    "            g.edge_type_subgraph(['atom_neighbors_atom']))\n",
    "        x = self.gn(g_sub, x)\n",
    "        return x        \n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, in_dim=128, out_dim=256, n_classes=45):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.d = torch.nn.Linear(in_dim, out_dim)\n",
    "        self.c = torch.nn.Linear(out_dim, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_hat = self.c(\n",
    "                torch.nn.functional.tanh(\n",
    "                    self.d(\n",
    "                        x)))\n",
    "        \n",
    "        return y_hat\n",
    "        \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, model, kwargs):\n",
    "        super(Net, self).__init__()\n",
    "        self.f_in = torch.nn.Sequential(\n",
    "            torch.nn.Linear(117, 64),\n",
    "            torch.nn.Tanh())\n",
    "        \n",
    "        self.gn0 = GN(model, kwargs)\n",
    "        self.gn1 = GN(model, kwargs)\n",
    "        self.gn2 = GN(model, kwargs)\n",
    "        \n",
    "        self.c = Classifier(64, 64, 45)\n",
    "        \n",
    "    def forward(self, g):\n",
    "        x = g.nodes['atom'].data['h0']\n",
    "        x = self.f_in(x)\n",
    "        x = self.gn0(g, x)\n",
    "        x = torch.nn.functional.tanh(x)\n",
    "        x = self.gn1(g, x)\n",
    "        x = torch.nn.functional.tanh(x)\n",
    "        x = self.gn2(g, x)\n",
    "        x = self.c(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import pytorch as dgl_pytorch\n",
    "net = Net(dgl_pytorch.conv.SAGEConv,  {'aggregator_type': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = torch.optim.Adam(list(net.parameters()) + list(classifier.parameters()), 1e-3)\n",
    "opt = torch.optim.Adam(list(net.parameters()), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangy1/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8970, grad_fn=<NllLossBackward>)\n",
      "tensor(3.6739, grad_fn=<NllLossBackward>)\n",
      "tensor(3.5260, grad_fn=<NllLossBackward>)\n",
      "tensor(3.3626, grad_fn=<NllLossBackward>)\n",
      "tensor(3.2505, grad_fn=<NllLossBackward>)\n",
      "tensor(3.1976, grad_fn=<NllLossBackward>)\n",
      "tensor(3.1707, grad_fn=<NllLossBackward>)\n",
      "tensor(3.0109, grad_fn=<NllLossBackward>)\n",
      "tensor(2.9323, grad_fn=<NllLossBackward>)\n",
      "tensor(2.9530, grad_fn=<NllLossBackward>)\n",
      "tensor(2.9488, grad_fn=<NllLossBackward>)\n",
      "tensor(2.7790, grad_fn=<NllLossBackward>)\n",
      "tensor(2.7172, grad_fn=<NllLossBackward>)\n",
      "tensor(2.7632, grad_fn=<NllLossBackward>)\n",
      "tensor(2.7719, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5985, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5506, grad_fn=<NllLossBackward>)\n",
      "tensor(2.6156, grad_fn=<NllLossBackward>)\n",
      "tensor(2.6389, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4621, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4269, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4934, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5321, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3539, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3356, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3885, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4425, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2617, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2537, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2970, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3605, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1765, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1689, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2113, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2799, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0917, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0826, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1262, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2011, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0072, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0452, grad_fn=<NllLossBackward>)\n",
      "tensor(2.1297, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9230, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9268, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9666, grad_fn=<NllLossBackward>)\n",
      "tensor(2.0602, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8416, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8537, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8914, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9919, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7691, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7848, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8199, grad_fn=<NllLossBackward>)\n",
      "tensor(1.9250, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6998, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7184, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7488, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8567, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6335, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6567, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6795, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7937, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5726, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5996, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6124, grad_fn=<NllLossBackward>)\n",
      "tensor(1.7331, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5136, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5471, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5476, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6736, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4568, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4928, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4886, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6173, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4028, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4373, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4340, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5649, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3509, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3883, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3788, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5152, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3015, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3362, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3279, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4661, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2496, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2842, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2750, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4148, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1980, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2242, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2201, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3637, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1450, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1676, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1684, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3133, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0938, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1144, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1167, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2663, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0449, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0633, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0686, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2196, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9978, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0181, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0214, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9754, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1285, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9356, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9363, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0863, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8767, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8992, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8978, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8418, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8648, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8626, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0088, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7788, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7740, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7742, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8826, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6979, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7199, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7251, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8553, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6737, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6946, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8296, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6506, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6803, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6479, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6590, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6078, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6261, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6383, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7593, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5877, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6182, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7375, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5856, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5989, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7165, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5497, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5667, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5803, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5318, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5485, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5624, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6770, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5148, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5312, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6585, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4985, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4830, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4997, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6235, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4681, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4852, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4986, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4539, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4714, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4845, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5908, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4403, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4583, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4273, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4458, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4150, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4339, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3919, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4118, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5189, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3810, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3913, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4939, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3816, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3903, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4822, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3506, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3805, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3411, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3632, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4602, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3319, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3622, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3229, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3536, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3296, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3373, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2907, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3220, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2834, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3067, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3147, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2763, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2996, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2695, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2926, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3771, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2630, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2941, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3690, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2566, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2792, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2877, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3612, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2814, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3536, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2665, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2388, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2605, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2695, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3389, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2332, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2547, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2638, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3318, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2278, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2584, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3249, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2225, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2531, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3182, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2174, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2382, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2479, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3116, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2330, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2430, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2078, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2382, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2990, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2336, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2930, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1989, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2187, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2291, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2871, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1946, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2142, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2248, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2814, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1906, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2758, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1866, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2058, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2703, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1829, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2649, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1793, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2089, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2596, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1758, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1903, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2494, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1692, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1867, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1661, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1832, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1948, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2397, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1630, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1799, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1916, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2350, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1601, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1766, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1884, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2304, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1853, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1704, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1823, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2215, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1518, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1674, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1793, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1645, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1765, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2130, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1616, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1737, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2089, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1440, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1588, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1710, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2048, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1684, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1392, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    for g, y in ds_tr:\n",
    "        opt.zero_grad()\n",
    "        # y_hat = classifier(net(g, return_graph=True))\n",
    "        y_hat = net(g)\n",
    "        loss = loss_fn(y_hat, torch.where(torch.gt(y, 0))[1])\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangy1/anaconda3/envs/env1/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for g, y in ds_tr:\n",
    "    y_hat = torch.argmax(net(g), dim=1)\n",
    "    y = torch.argmax(y, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_cm = pd.DataFrame(confusion_matrix(y, y_hat, labels=list(range(1, 46))),\n",
    "    [v for k, v in idx_to_element.items()],\n",
    "    [v for k, v in idx_to_element.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c448767d5af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(15, 15))\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
