Sender: LSF System <lsfadmin@lt22>
Subject: Job 13863105: <gcn_qm9> in cluster <lila> Exited

Job <gcn_qm9> was submitted from host <lilac-ln02> by user <wangy1> in cluster <lila> at Sat Feb 15 21:52:01 2020
Job was executed on host(s) <12*lt22>, in queue <gpuqueue>, as user <wangy1> in cluster <lila> at Sat Feb 15 21:52:02 2020
</home/wangy1> was used as the home directory.
</data/chodera/wangyq/hgfp_scripts/qm9> was used as the working directory.
Started at Sat Feb 15 21:52:02 2020
Terminated at Sat Feb 15 22:09:57 2020
Results reported at Sat Feb 15 22:09:57 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -q gpuqueue
#BSUB -J gcn_qm9
#BSUB -m "ld-gpu ls-gpu lt-gpu lp-gpu lg-gpu lv-gpu lu-gpu"
#BSUB -q gpuqueue -n 12 -gpu "num=1:j_exclusive=yes"
#BSUB -R "rusage[mem=4] span[hosts=1]"
#BSUB -W 8:00
#BSUB -o %J.stdout
#BSUB -eo %J.stderr

python ../../hgfp/hgfp/app/supervised_train.py --model gcn --batch_size 32 --n_batches_te 418 --n_batches_vl 418 --config 32 'tanh' 32 'tanh' 1 --learning_rate 1e-3 --n_epochs 30

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1635.18 sec.
    Max Memory :                                 1 GB
    Average Memory :                             0.88 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               47.00 GB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                55
    Run time :                                   1076 sec.
    Turnaround time :                            1076 sec.

The output (if any) follows:



PS:

Read file <13863105.stderr> for stderr output of this job.

